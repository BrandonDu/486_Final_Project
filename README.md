@ -1,547 +0,0 @@
[![pypi](https://img.shields.io/pypi/v/spflow.svg)](https://pypi.org/project/spflow/)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Build Status](https://travis-ci.com/SPFlow/SPFlow.svg?branch=master)](https://travis-ci.com/SPFlow/SPFlow)


# Ruben Carpenter, Brandon Du, Ayush Tibrewal 486 Final Project: Sum-Product Networks


## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes.

## Examples

We start by creating an SPN. Using a Domain-Specific Language, we can create an SPN of categorical
leave nodes like this:


```python
from spn.structure.leaves.parametric.Parametric import Categorical

spn = 0.4 * (Categorical(p=[0.2, 0.8], scope=0) *
             (0.3 * (Categorical(p=[0.3, 0.7], scope=1) *
                     Categorical(p=[0.4, 0.6], scope=2))
            + 0.7 * (Categorical(p=[0.5, 0.5], scope=1) *
                     Categorical(p=[0.6, 0.4], scope=2)))) \
    + 0.6 * (Categorical(p=[0.2, 0.8], scope=0) *
             Categorical(p=[0.3, 0.7], scope=1) *
             Categorical(p=[0.4, 0.6], scope=2))
```

We can create the same SPN using the object hierarchy:

```python
from spn.structure.leaves.parametric.Parametric import Categorical

from spn.structure.Base import Sum, Product

from spn.structure.Base import assign_ids, rebuild_scopes_bottom_up


p0 = Product(children=[Categorical(p=[0.3, 0.7], scope=1), Categorical(p=[0.4, 0.6], scope=2)])
p1 = Product(children=[Categorical(p=[0.5, 0.5], scope=1), Categorical(p=[0.6, 0.4], scope=2)])
s1 = Sum(weights=[0.3, 0.7], children=[p0, p1])
p2 = Product(children=[Categorical(p=[0.2, 0.8], scope=0), s1])
p3 = Product(children=[Categorical(p=[0.2, 0.8], scope=0), Categorical(p=[0.3, 0.7], scope=1)])
p4 = Product(children=[p3, Categorical(p=[0.4, 0.6], scope=2)])
spn = Sum(weights=[0.4, 0.6], children=[p2, p4])

assign_ids(spn)
rebuild_scopes_bottom_up(spn)
```

The p parameter indicates the probabilities, and the scope indicates the variable we are modeling.


We can now visualize the SPN using:

```python
from spn.io.Graphics import plot_spn

plot_spn(spn, 'basicspn.png')
```

![basicspn.png](https://github.com/SPFlow/SPFlow/blob/master/Documentation/basicspn.png)

Marginalizing an SPN means summing out all the other non-relevant variables.
So, if we want to marginalize the above SPN and sum out all other variables leaving only variables 1 and 2, we can do:

```python
from spn.algorithms.Marginalization import marginalize

spn_marg = marginalize(spn, [1,2])
```
Here, we marginalize all the variables not in [1,2], and create a *NEW* structure that knows nothing about the previous one
nor about the variable 0.

We can use this new spn to do all the operations we are interested in. That means, we can also plot it!
```python
plot_spn(spn_marg, 'marginalspn.png')
```
![basicspn.png](https://github.com/SPFlow/SPFlow/blob/master/Documentation/marginalspn.png)

We can also dump the SPN as text:
```python
from spn.io.Text import spn_to_str_equation
txt = spn_to_str_equation(spn_marg)
print(txt)
```
And the output is:
```python
(0.6*((Categorical(V1|p=[0.3, 0.7]) * Categorical(V2|p=[0.4, 0.6]))) + 0.12000000000000002*((Categorical(V1|p=[0.3, 0.7]) * Categorical(V2|p=[0.4, 0.6]))) + 0.27999999999999997*((Categorical(V1|p=[0.5, 0.5]) * Categorical(V2|p=[0.6, 0.4]))))
```

We consider SPN for classification, by learning an SPN from data and then comparing the probabilities for the given classes. In particular, we perform classification via approximate most probable explanation (MPE). 

First, we consider the following problem of classifying points into clusters using the following dataset generated by 5 Gaussians.

![basicspn.png](https://github.com/BrandonDu/486_Final_Project/blob/main/src/Gaussian_Clusters_1.png)


```python
np.random.seed(42)
def generate_data(mu_x, std_x, mu_y, std_y, num_points, label):
    X = np.random.normal(mu_x, std_x, num_points)
    Y = np.random.normal(mu_y, std_y, num_points)
    return np.column_stack((X, Y, np.full(num_points, label)))

clusters = [
        {"mean_x": 1, "std_x": 0.6, "mean_y": 4, "std_y": 1.6, "label": 0},  # Cluster 0
        {"mean_x": -3, "std_x": 0.8, "mean_y": -4, "std_y": 1.7, "label": 1},  # Cluster 1
        {"mean_x": 5, "std_x": 0.6, "mean_y": -8, "std_y": 1.6, "label": 2},  # Cluster 2
        {"mean_x": 8, "std_x": 0.5, "mean_y": 9, "std_y": 1, "label": 3},  # Cluster 3
        {"mean_x": -10, "std_x": 0.7, "mean_y": 1, "std_y": 1.4, "label": 4},  # Cluster 4
    ]
data = np.array(
            [
                generate_data(
                    cluster["mean_x"],
                    cluster["std_x"],
                    cluster["mean_y"],
                    cluster["std_y"],
                    num_points,
                    clusters.index(cluster),
                )
                for cluster in clusters
            ]
        )
train_data = data.reshape(num_clusters * num_points, 3)
```

We then learn an SPN from the training data:

```python
from spn.algorithms.LearningWrappers import learn_parametric, learn_classifier
from spn.structure.leaves.parametric.Parametric import Categorical, Gaussian
from spn.structure.Base import Context
spn_classification = learn_classifier(train_data,
                       Context(parametric_types=[Gaussian, Gaussian, Categorical]).add_domains(train_data),
                       learn_parametric, 2)
```
We model our problem as containing 3 features: 2 Gaussians for each of the coordinates and one Categorical for the label. 
We specify that the label is in column 2 (0-indexed), and we generate a basic SPN, which we show below

![basicspn.png](https://github.com/BrandonDu/486_Final_Project/blob/main/src/Example%201%20SPN.png)

Now, we test the classification with an i.i.d dataset, as well as a rectangular lattice of points that are 0.5 apart. We color the classification and find the accuracy for the first dataset.

```python
num_test_points = 10
test_data = np.array(
    [
        generate_data(
            cluster["mean_x"],
            cluster["std_x"],
            cluster["mean_y"],
            cluster["std_y"],
            num_test_points,
            clusters.index(cluster),
        )
        for cluster in clusters
    ]
).reshape(num_clusters * num_test_points, 3)
test_classification = np.copy(test_data)
test_classification[:, -1] = np.nan
```

As previously stated, we do classification via mpe
```python
classification = mpe(spn_classification, test_classification)
```
We plot and color the results
![](https://github.com/BrandonDu/486_Final_Project/blob/main/src/Classification.png)

As we see, all points are classified correctly. 

Now for a grid, we similar find that the SPN performs extremely well.
![](https://github.com/BrandonDu/486_Final_Project/blob/main/src/Grid%20Classification%20Example%201.png)

### Utilities

Finally, we have some basic utilities for working with SPNs:

We can make sure that the SPN that we are using is valid, that is, it is consistent and complete.
```python
from spn.algorithms.Validity import is_valid
print(is_valid(spn))
```
The output indicates that the SPN is valid and there are no debugging error messages:
```python
(True, None)
```

To compute basic statistics on the structure of the SPN:
```python
from spn.algorithms.Statistics import get_structure_stats
print(get_structure_stats(spn))
```



## Citation
If you find SPFlow useful please cite us in your work:
```
@misc{Molina2019SPFlow,
  Author = {Alejandro Molina and Antonio Vergari and Karl Stelzner and Robert Peharz and Pranav Subramani and Nicola Di Mauro and Pascal Poupart and Kristian Kersting},
  Title = {SPFlow: An Easy and Extensible Library for Deep Probabilistic Learning using Sum-Product Networks},
  Year = {2019},
  Eprint = {arXiv:1901.03704},
}
```

## Authors

* **Alejandro Molina** - *TU Darmstadt*
* **Antonio Vergari** - *Max-Planck-Institute*
* **Karl Stelzner** - *TU Darmstadt*
* **Robert Peharz** - *University of Cambridge*
* **Nicola Di Mauro** - *University of Bari Aldo Moro*
* **Kristian Kersting** - *TU Darmstadt*

See also the list of [contributors](https://github.com/alejandromolinaml/SPFlow/contributors) who participated in this project.

## Contributors

* **Moritz Kulessa** - *TU Darmstadt*
* **Claas Voelcker** - *TU Darmstadt*
* **Simon Roesler** - *Karlsruhe Institute of Technology*
* **Steven Lang** - *TU Darmstadt*
* **Alexander L. Hayes** - *Indiana University, Bloomington*

## License

This project is licensed under the Apache License, Version 2.0 - see the [LICENSE.md](LICENSE.md) file for details



## Acknowledgments
<img src="https://github.com/SPFlow/SPFlow/blob/master/Documentation/acknowledgements/bmbf.png" height="100"/><img src="https://github.com/SPFlow/SPFlow/blob/master/Documentation/acknowledgements/dfg.jpg"  height="100"/><img src="https://github.com/SPFlow/SPFlow/blob/master/Documentation/acknowledgements/euc.png"  height="100"/>
* Parts of SPFlow as well as its motivating research have been supported by the Germany Science Foundation (DFG) - AIPHES, GRK 1994, and CAML, KE 1686/3-1 as part of SPP 1999- and the Federal Ministry of Education and Research (BMBF) - InDaS, 01IS17063B.

* This project received funding from the European Union's Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie Grant Agreement No. 797223 (HYBSPN).
